Use labeled datasets to train a model to predict the outcomes. Generally, there are two main types of supervised learning problems, including regression and classification.

Regression: predict a number, such as the length of a table. There have been many regression methods, such as linear regression, logistic regression, polynomial regression, stepwise regression, Lasso regression, and elastic net regression.

Linear regression predicts the value of a variable based on a linear relationship of the values of the others. Linear regression works well when data are linearly separable.

Logistic regression is to predict the parameters of a logistic model.

Polynomial regression can be used to model non-linearly separable data.

Stepwise regression

Lasso regression


Classification: predict a state, such as a music genre (Jazz, Rock, etc.). Generally, there are four types of classification tasks, including (1) binary classification, (2) multi-class classification, (3) multi-label classification, and (4) imbalanced classification. So far, there have been many classification methods, such as support vector machines, Naive Bayes, and k-Nearest Neighbors.

The idea of support vector machines is to find a hyperplane that divides the given data instances into two categories, aiming to maximizing the width of the gap between the two categories.

Navie Bayes is a conditional probability model, which is based on Bayes' theorem. Bayes' theorem describes the probability of an event, based on prior knowledge of conditions that might be relevant to the particular event. The Naive Bayes classifier assumes that the value of a feature is independent of those of other features.

The idea of k-Nearest Neighbors is to classify an instance based on the plurality vote of its k neighbors.
